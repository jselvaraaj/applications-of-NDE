{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1MCoK2o6ARZaF-2EIN0Eu7aSX4tOtrW9o","timestamp":1677182560423}],"mount_file_id":"1QAVJkk7X-J0f6-ClDzNkmOZyEhnsBtnK","authorship_tag":"ABX9TyMHjDikD481Ku2gJd576xpm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd drive/MyDrive/Honors/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GAZiAj_JWb_I","executionInfo":{"status":"ok","timestamp":1677425538358,"user_tz":300,"elapsed":8451,"user":{"displayName":"Joseph Daniel Selvaraaj","userId":"01267249207347429283"}},"outputId":"c833e7cf-0809-4b87-9328-e3dbb6464332"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/Honors\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"],"metadata":{"id":"2TouZd1Y4lMo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"S4p41cih4p04"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"mG6si6sb6DJZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["######################\n","# So you want to train a Neural CDE model?\n","# Let's get started!\n","######################\n","\n","import math\n","import torch\n","import torchcde\n","\n","\n","######################\n","# A CDE model looks like\n","#\n","# z_t = z_0 + \\int_0^t f_\\theta(z_s) dX_s\n","#\n","# Where X is your data and f_\\theta is a neural network. So the first thing we need to do is define such an f_\\theta.\n","# That's what this CDEFunc class does.\n","# Here we've built a small single-hidden-layer neural network, whose hidden layer is of width 128.\n","######################\n","class CDEFunc(torch.nn.Module):\n","    def __init__(self, input_channels, hidden_channels):\n","        ######################\n","        # input_channels is the number of input channels in the data X. (Determined by the data.)\n","        # hidden_channels is the number of channels for z_t. (Determined by you!)\n","        ######################\n","        super(CDEFunc, self).__init__()\n","        self.input_channels = input_channels\n","        self.hidden_channels = hidden_channels\n","\n","        self.linear1 = torch.nn.Linear(hidden_channels, 128)\n","        self.linear2 = torch.nn.Linear(128, input_channels * hidden_channels)\n","\n","    ######################\n","    # For most purposes the t argument can probably be ignored; unless you want your CDE to behave differently at\n","    # different times, which would be unusual. But it's there if you need it!\n","    ######################\n","    def forward(self, t, z):\n","        # z has shape (batch, hidden_channels)\n","        z = self.linear1(z)\n","        z = z.relu()\n","        z = self.linear2(z)\n","        ######################\n","        # Easy-to-forget gotcha: Best results tend to be obtained by adding a final tanh nonlinearity.\n","        ######################\n","        z = z.tanh()\n","        ######################\n","        # Ignoring the batch dimension, the shape of the output tensor must be a matrix,\n","        # because we need it to represent a linear map from R^input_channels to R^hidden_channels.\n","        ######################\n","        z = z.view(z.size(0), self.hidden_channels, self.input_channels)\n","        return z\n","\n","\n","######################\n","# Next, we need to package CDEFunc up into a model that computes the integral.\n","######################\n","class NeuralCDE(torch.nn.Module):\n","    def __init__(self, input_channels, hidden_channels, output_channels, interpolation=\"cubic\"):\n","        super(NeuralCDE, self).__init__()\n","\n","        self.func = CDEFunc(input_channels, hidden_channels)\n","        self.initial = torch.nn.Linear(input_channels, hidden_channels)\n","        self.readout = torch.nn.Linear(hidden_channels, output_channels)\n","        self.interpolation = interpolation\n","\n","    def forward(self, coeffs):\n","        if self.interpolation == 'cubic':\n","            X = torchcde.CubicSpline(coeffs)\n","        elif self.interpolation == 'linear':\n","            X = torchcde.LinearInterpolation(coeffs)\n","        else:\n","            raise ValueError(\"Only 'linear' and 'cubic' interpolation methods are implemented.\")\n","\n","        ######################\n","        # Easy to forget gotcha: Initial hidden state should be a function of the first observation.\n","        ######################\n","        X0 = X.evaluate(X.interval[0])\n","        z0 = self.initial(X0)\n","\n","        ######################\n","        # Actually solve the CDE.\n","        ######################\n","        z_T = torchcde.cdeint(X=X,\n","                              z0=z0,\n","                              func=self.func,\n","                              t=X.interval)\n","\n","        ######################\n","        # Both the initial value and the terminal value are returned from cdeint; extract just the terminal value,\n","        # and then apply a linear map.\n","        ######################\n","        z_T = z_T[:, 1]\n","        pred_y = self.readout(z_T)\n","        return pred_y\n","\n","\n","######################\n","# Now we need some data.\n","# Here we have a simple example which generates some spirals, some going clockwise, some going anticlockwise.\n","######################\n","def get_data(num_timepoints=100):\n","    t = torch.linspace(0., 4 * math.pi, num_timepoints)\n","\n","    start = torch.rand(128) * 2 * math.pi\n","    x_pos = torch.cos(start.unsqueeze(1) + t.unsqueeze(0)) / (1 + 0.5 * t)\n","    x_pos[:64] *= -1\n","    y_pos = torch.sin(start.unsqueeze(1) + t.unsqueeze(0)) / (1 + 0.5 * t)\n","    x_pos += 0.01 * torch.randn_like(x_pos)\n","    y_pos += 0.01 * torch.randn_like(y_pos)\n","    ######################\n","    # Easy to forget gotcha: time should be included as a channel; Neural CDEs need to be explicitly told the\n","    # rate at which time passes. Here, we have a regularly sampled dataset, so appending time is pretty simple.\n","    ######################\n","    X = torch.stack([t.unsqueeze(0).repeat(128, 1), x_pos, y_pos], dim=2)\n","    y = torch.zeros(128)\n","    y[:64] = 1\n","\n","    perm = torch.randperm(128)\n","    X = X[perm]\n","    y = y[perm]\n","\n","    ######################\n","    # X is a tensor of observations, of shape (batch=128, sequence=100, channels=3)\n","    # y is a tensor of labels, of shape (batch=128,), either 0 or 1 corresponding to anticlockwise or clockwise\n","    # respectively.\n","    ######################\n","    return X, y\n","\n","\n","def main(num_epochs=30):\n","    train_X, train_y = get_data()\n","\n","    ######################\n","    # input_channels=3 because we have both the horizontal and vertical position of a point in the spiral, and time.\n","    # hidden_channels=8 is the number of hidden channels for the evolving z_t, which we get to choose.\n","    # output_channels=1 because we're doing binary classification.\n","    ######################\n","    model = NeuralCDE(input_channels=3, hidden_channels=8, output_channels=1)\n","    optimizer = torch.optim.Adam(model.parameters())\n","\n","    ######################\n","    # Now we turn our dataset into a continuous path. We do this here via Hermite cubic spline interpolation.\n","    # The resulting `train_coeffs` is a tensor describing the path.\n","    # For most problems, it's probably easiest to save this tensor and treat it as the dataset.\n","    ######################\n","    train_coeffs = torchcde.hermite_cubic_coefficients_with_backward_differences(train_X)\n","\n","    train_dataset = torch.utils.data.TensorDataset(train_coeffs, train_y)\n","    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=32)\n","    for epoch in range(num_epochs):\n","        for batch in train_dataloader:\n","            batch_coeffs, batch_y = batch\n","            pred_y = model(batch_coeffs).squeeze(-1)\n","            loss = torch.nn.functional.binary_cross_entropy_with_logits(pred_y, batch_y)\n","            loss.backward()\n","            optimizer.step()\n","            optimizer.zero_grad()\n","        print('Epoch: {}   Training loss: {}'.format(epoch, loss.item()))\n","\n","    test_X, test_y = get_data()\n","    test_coeffs = torchcde.hermite_cubic_coefficients_with_backward_differences(test_X)\n","    pred_y = model(test_coeffs).squeeze(-1)\n","    binary_prediction = (torch.sigmoid(pred_y) > 0.5).to(test_y.dtype)\n","    prediction_matches = (binary_prediction == test_y).to(test_y.dtype)\n","    proportion_correct = prediction_matches.sum() / test_y.size(0)\n","    print('Test Accuracy: {}'.format(proportion_correct))\n","\n","\n","if __name__ == '__main__':\n","    main()"],"metadata":{"id":"f-r5WtB0WKFv"},"execution_count":null,"outputs":[]}]}